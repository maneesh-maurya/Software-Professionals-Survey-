{"cells":[{"cell_type":"markdown","metadata":{"id":"TgcMCmuY2iuN"},"source":["# **Web Scraping Lab**\n"]},{"cell_type":"markdown","metadata":{"id":"Yr9wC8vq2iuT"},"source":["## Objectives\n"]},{"cell_type":"markdown","metadata":{"id":"LOhdbC_V2iuV"},"source":["After completing this lab you will be able to:\n"]},{"cell_type":"markdown","metadata":{"id":"4jmv5Qgi2iuX"},"source":["* Download a webpage using requests module\n","* Scrape all links from a web page\n","* Scrape all image urls from a web page\n","* Scrape data from html tables\n"]},{"cell_type":"markdown","metadata":{"id":"T8VeKoc72iud"},"source":["Import the required modules and functions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i-OVl8vR2iuh"},"outputs":[],"source":["from bs4 import BeautifulSoup # this module helps in web scrapping.\n","import requests  # this module helps us to download a web page"]},{"cell_type":"markdown","metadata":{"id":"g1zRgH342iun"},"source":["Download the contents of the web page\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e0oGA10X2iur"},"outputs":[],"source":["url = \"http://www.ibm.com\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4k0zLjoV2iuu"},"outputs":[],"source":["# get the contents of the webpage in text format and store in a variable called data\n","data  = requests.get(url).text"]},{"cell_type":"markdown","metadata":{"id":"53_Q3ovC2iuw"},"source":["Create a soup object using the class BeautifulSoup\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7KBhjdw92iuy"},"outputs":[],"source":["soup = BeautifulSoup(data,\"html5lib\")  # create a soup object using the variable 'data'"]},{"cell_type":"markdown","metadata":{"id":"T9RKHEWW2iu0"},"source":["Scrape all links\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xl9Nar_Z2iu1"},"outputs":[],"source":["for link in soup.find_all('a'):  # in html anchor/link is represented by the tag <a>\n","    print(link.get('href'))"]},{"cell_type":"markdown","metadata":{"id":"7TCx1STM2iu3"},"source":["Scrape  all images\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FMULxmjt2iu4"},"outputs":[],"source":["for link in soup.find_all('img'):# in html image is represented by the tag <img>\n","    print(link.get('src'))"]},{"cell_type":"markdown","metadata":{"id":"FMwJcLq32iu7"},"source":["## Scrape data from html tables\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tUvx1nyD2iu8"},"outputs":[],"source":["#The below url contains a html table with data about colors and color codes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EXKTaBa_2iu9"},"outputs":[],"source":["url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\""]},{"cell_type":"markdown","metadata":{"id":"Z7H3Dakf2iu_"},"source":["Before proceeding to scrape a web site, you need to examine the contents, and the way data is organized on the website. Open the above url in your browser and check how many rows and columns are there in the color table.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7wZ-a0x72ivB"},"outputs":[],"source":["# get the contents of the webpage in text format and store in a variable called data\n","data  = requests.get(url).text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bmvGCBm42ivD"},"outputs":[],"source":["soup = BeautifulSoup(data,\"html5lib\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"liCJIoFO2ivE"},"outputs":[],"source":["#find a html table in the web page\n","table = soup.find('table') # in html table is represented by the tag <table>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LKyATVbt2ivF"},"outputs":[],"source":["#Get all rows from the table\n","for row in table.find_all('tr'): # in html table row is represented by the tag <tr>\n","    # Get all columns in each row.\n","    cols = row.find_all('td') # in html a column is represented by the tag <td>\n","    color_name = cols[2].getText() # store the value in column 3 as color_name\n","    color_code = cols[3].getText() # store the value in column 4 as color_code\n","    print(\"{}--->{}\".format(color_name,color_code))"]},{"cell_type":"markdown","metadata":{"id":"_3G9_zvz2ivH"},"source":["### Other Contributors\n"]},{"cell_type":"markdown","metadata":{"id":"l_9aUa5S2ivJ"},"source":["Rav Ahuja\n"]},{"cell_type":"markdown","metadata":{"id":"0cc5_PRK2ivL"},"source":["## Change Log\n"]},{"cell_type":"markdown","metadata":{"id":"73juIebK2ivM"},"source":["|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2020-10-17  | 0.1  | Ramesh Sannareddy  |  Created initial version of the lab |\n"]},{"cell_type":"markdown","metadata":{"id":"8XMVQMmU2ivM"},"source":[" Copyright &copy; 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01).\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}